{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95acb005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Flask in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Collecting pdfminer.six\n",
      "  Obtaining dependency information for pdfminer.six from https://files.pythonhosted.org/packages/67/7d/44d6b90e5a293d3a975cefdc4e12a932ebba814995b2a07e37e599dd27c6/pdfminer.six-20240706-py3-none-any.whl.metadata\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting python-docx\n",
      "  Obtaining dependency information for python-docx from https://files.pythonhosted.org/packages/3e/3d/330d9efbdb816d3f60bf2ad92f05e1708e4a1b9abe80461ac3444c83f749/python_docx-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Flask) (8.0.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Collecting typing-extensions>=4.9.0 (from python-docx)\n",
      "  Obtaining dependency information for typing-extensions>=4.9.0 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\thila\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.0->Flask) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->Flask) (2.1.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
      "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.6 MB 131.3 kB/s eta 0:00:43\n",
      "   ---------------------------------------- 0.0/5.6 MB 163.8 kB/s eta 0:00:35\n",
      "   ---------------------------------------- 0.0/5.6 MB 178.6 kB/s eta 0:00:32\n",
      "    --------------------------------------- 0.1/5.6 MB 262.6 kB/s eta 0:00:22\n",
      "    --------------------------------------- 0.1/5.6 MB 327.7 kB/s eta 0:00:17\n",
      "    --------------------------------------- 0.1/5.6 MB 393.8 kB/s eta 0:00:14\n",
      "   - -------------------------------------- 0.2/5.6 MB 456.4 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.2/5.6 MB 428.8 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.2/5.6 MB 468.6 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.2/5.6 MB 465.5 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.3/5.6 MB 491.5 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.3/5.6 MB 455.5 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.3/5.6 MB 478.3 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.3/5.6 MB 480.0 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.3/5.6 MB 491.9 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.4/5.6 MB 491.5 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.4/5.6 MB 524.5 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.5/5.6 MB 521.7 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.5/5.6 MB 538.3 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.5/5.6 MB 544.2 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 0.6/5.6 MB 562.0 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.6/5.6 MB 575.1 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.6/5.6 MB 578.5 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.7/5.6 MB 600.2 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 0.7/5.6 MB 602.4 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 0.7/5.6 MB 604.8 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 0.8/5.6 MB 615.2 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.8/5.6 MB 624.4 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 0.9/5.6 MB 632.4 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 0.9/5.6 MB 633.6 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 0.9/5.6 MB 641.3 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.0/5.6 MB 655.4 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.0/5.6 MB 661.9 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.1/5.6 MB 674.5 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.1/5.6 MB 686.8 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.2/5.6 MB 698.0 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.2/5.6 MB 708.6 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 1.3/5.6 MB 724.4 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 1.3/5.6 MB 722.6 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 1.4/5.6 MB 727.5 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 1.4/5.6 MB 724.3 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 1.4/5.6 MB 728.1 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 1.5/5.6 MB 736.9 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 749.0 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 749.0 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 744.9 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 1.7/5.6 MB 748.4 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 1.7/5.6 MB 755.5 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 1.8/5.6 MB 761.8 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 1.8/5.6 MB 773.2 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 1.9/5.6 MB 779.8 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 1.9/5.6 MB 794.2 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 2.0/5.6 MB 799.7 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 2.0/5.6 MB 801.1 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 2.1/5.6 MB 802.4 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 2.2/5.6 MB 819.2 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 2.2/5.6 MB 816.3 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 2.2/5.6 MB 825.9 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 2.3/5.6 MB 822.2 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 2.3/5.6 MB 826.6 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 2.4/5.6 MB 830.9 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 2.4/5.6 MB 838.7 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 2.5/5.6 MB 842.6 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 2.5/5.6 MB 839.7 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 2.6/5.6 MB 848.0 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 2.7/5.6 MB 858.3 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 2.7/5.6 MB 858.5 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 2.8/5.6 MB 864.3 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 2.8/5.6 MB 869.6 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 2.9/5.6 MB 873.9 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 2.9/5.6 MB 884.3 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 3.0/5.6 MB 887.1 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 3.1/5.6 MB 894.7 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 3.1/5.6 MB 899.8 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 3.2/5.6 MB 904.0 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.2/5.6 MB 909.4 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.3/5.6 MB 911.7 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.4/5.6 MB 919.9 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 3.4/5.6 MB 924.8 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 3.5/5.6 MB 929.7 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.6/5.6 MB 937.1 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 3.6/5.6 MB 949.6 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 3.7/5.6 MB 956.6 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.7/5.6 MB 956.9 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.8/5.6 MB 962.3 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.8/5.6 MB 961.3 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 3.9/5.6 MB 968.0 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.0/5.6 MB 976.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.1/5.6 MB 980.6 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.2/5.6 MB 989.2 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.2/5.6 MB 997.5 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 4.3/5.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.4/5.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 4.4/5.6 MB 1.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 4.5/5.6 MB 1.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 4.6/5.6 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 4.6/5.6 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.6 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.8/5.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.8/5.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.9/5.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.0/5.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.1/5.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.1/5.6 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.3/5.6 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.4/5.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "   ---------------------------------------- 0.0/244.3 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 92.2/244.3 kB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 143.4/244.3 kB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 235.5/244.3 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 244.3/244.3 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, python-docx, pdfminer.six\n",
      "Successfully installed pdfminer.six-20240706 python-docx-1.1.2 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "#Install the Required Libraries:\n",
    "!pip install Flask scikit-learn requests beautifulsoup4 nltk transformers pdfminer.six python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf526f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the Libraries:\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924ea455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract from PDF\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43dc2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract from docx\n",
    "from docx import Document\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58e05229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Text\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_text(text):\n",
    "    # Check if the input is a list and join it into a single string\n",
    "    if isinstance(text, list):\n",
    "        text = ' '.join(text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase and tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a062cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Text to TF-IDF Vectors:\n",
    "#TF-IDF (Term Frequency-Inverse Document Frequency) is a way to represent text in numerical form:\n",
    "def vectorize_text(text_list):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(text_list)\n",
    "    return vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ccde712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vectors):\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "    return cosine_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46436b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_resumes(new_resume_text, existing_resumes):\n",
    "    all_texts = [new_resume_text] + existing_resumes\n",
    "    vectors = vectorize_text(all_texts)\n",
    "    cosine_matrix = calculate_cosine_similarity(vectors)\n",
    "    return cosine_matrix[0, 1:]  # Similarities with all other resumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bce4128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_online(text_snippet):\n",
    "    query = '+'.join(text_snippet.split())\n",
    "    url = f\"https://www.google.com/search?q={query}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup.find_all('a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b0cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(links):\n",
    "    urls = []\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href and \"url?q=\" in href:\n",
    "            urls.append(href.split(\"url?q=\")[1].split(\"&\")[0])\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70b77c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_plagiarism_score(similarity_scores):\n",
    "    return sum(similarity_scores) / len(similarity_scores)\n",
    "def calculate_overall_score(plagiarism_score, num_sources):\n",
    "    return (plagiarism_score + num_sources) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "469d37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting plagiarism detection...\n",
      "Extracted new resume text (first 500 characters): THILAK SUJATHA KRISHNAMURTHY \n",
      "+1 (838) 218-7324 | thilak280400@gmail.com | LinkedIn |Tempe, AZ \n",
      "\n",
      "SUMMARY \n",
      "\n",
      "Software Engineer with over 2 years of experience specializing in cloud-based and containerized software solutions. \n",
      "Successfully led projects improving functionality and scalability using Python, Java, and AWS, Docker, and Kubernetes. \n",
      "Proven track record in using JavaScript and optimizing data integration processes. Seeking to leverage skills in software \n",
      "development and workflow automati\n",
      "Cleaned new resume text (first 10 tokens): ['thilak', 'sujatha', 'krishnamurthy', '1', '838', '2187324', 'thilak280400gmailcom', 'linkedin', 'tempe', 'az']\n",
      "Extracted and cleaned existing resume text (first 10 tokens): ['thilak', 'sujatha', 'krishnamurthy', '1', '838', '2187324', 'thilak280400gmailcom', 'linkedin', 'tempe', 'az']\n",
      "Extracted and cleaned existing resume text (first 10 tokens): ['thilak', 'sujatha', 'krishnamurthy', '1', '838', '2187324', 'thilak280400gmailcom', 'linkedin', 'tempe', 'az']\n",
      "Extracted and cleaned existing resume text (first 10 tokens): ['thilak', 'sujatha', 'krishnamurthy', 'arizona', 'usa', '18382187324', 'thilak280400gmailcom', 'httpswwwlinkedincominthilaksujathakrishnamurthya611ba180', 'summary', 'senior']\n",
      "Similarity scores: [0.95708583 0.94694924 0.86243154]\n",
      "Plagiarism score: 0.9221555335919019\n",
      "Snippet: thilak, Number of URLs found: 17\n",
      "Snippet: sujatha, Number of URLs found: 14\n",
      "Snippet: krishnamurthy, Number of URLs found: 23\n",
      "Snippet: 1, Number of URLs found: 16\n",
      "Snippet: 838, Number of URLs found: 13\n",
      "Overall score: 36.96107776679595\n",
      "Plagiarism Score: 0.9221555335919019\n",
      "Number of Sources Found: 73\n",
      "Overall Score: 36.96107776679595\n",
      "Sources Found:\n",
      "http://www.rohanrhythm.com/\n",
      "https://www.reddit.com/r/Albany/comments/au8xsh/has_anyone_actually_seen_an_838_area_code_yet/\n",
      "https://www.youtube.com/watch%3Fv%3D_yHn-954iVQ\n",
      "https://en.wikipedia.org/wiki/Sujatha_(actress)\n",
      "https://www.instagram.com/rameshthilak/%3Fhl%3Den\n",
      "https://open.spotify.com/artist/2JEjaa7hWhE1BbL3OcoeFR\n",
      "https://maps.google.com/maps%3Fq%3Dkrishnamurthy%26um%3D1%26ie%3DUTF-8%26ved%3D1t:200713%26ictx%3D111\n",
      "https://www.mymichigan.org/doctors/find-a-doctor-basic-profile/chander-thilak/\n",
      "https://vikram.ece.cornell.edu/\n",
      "https://accounts.google.com/ServiceLogin%3Fcontinue%3Dhttps://www.google.com/search%253Fq%253Dsujatha%26hl%3Den\n",
      "https://www.aurahealth.io/blog/838-angel-number-meaning\n",
      "https://accounts.google.com/ServiceLogin%3Fcontinue%3Dhttps://www.google.com/search%253Fq%253D838%26hl%3Den\n",
      "https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den\n",
      "https://www.sujathabaliga.com/\n",
      "https://en.wikipedia.org/wiki/Tilak_Shekar\n",
      "https://www.cs.washington.edu/people/faculty/arvind\n",
      "https://www.imdb.com/name/nm2786589/\n",
      "https://www.linkedin.com/in/thilaktp\n",
      "https://en.wikipedia.org/wiki/Sujatha_(writer)\n",
      "/search%3Fq%3D1%26sca_esv%3D8073e08529232501%26sca_upv%3D1%26tbm%3Dshop%26source%3Dlnms%26ved%3D1t:200713%26ictx%3D111\n",
      "https://en.wikipedia.org/wiki/Helen_Nearing\n",
      "https://www.cs.washington.edu/people/faculty/arvind/publications\n",
      "https://maps.google.com/maps%3Fq%3D1%26um%3D1%26ie%3DUTF-8%26ved%3D1t:200713%26ictx%3D111\n",
      "/search%3Fq%3Dthilak%26sca_esv%3D969c93d55fac3d4d%26sca_upv%3D1%26tbm%3Dshop%26source%3Dlnms%26ved%3D1t:200713%26ictx%3D111\n",
      "https://www.imdb.com/name/nm5654687/\n",
      "https://www.sujathabaliga.com/about\n",
      "https://en.wikipedia.org/wiki/838\n",
      "https://providers.hf.org/provider/rajasri-krishnamurthy/953831\n",
      "https://accounts.google.com/ServiceLogin%3Fcontinue%3Dhttps://www.google.com/search%253Fq%253Dkrishnamurthy%26hl%3Den\n",
      "https://www.allareacodes.com/838\n",
      "https://en.wikipedia.org/wiki/1\n",
      "https://www.instagram.com/travel_with_thilak/\n",
      "https://www.wirefly.com/area-codes/838\n",
      "https://www.imdb.com/name/nm0837674/\n",
      "https://www.law.berkeley.edu/our-faculty/faculty-profiles/prasad-krishnamurthy/\n",
      "https://www.openphone.com/local-numbers/new-york/838-area-code\n",
      "https://maps.google.com/maps%3Fq%3Dsujatha%26um%3D1%26ie%3DUTF-8%26ved%3D1t:200713%26ictx%3D111\n",
      "https://en.wikipedia.org/wiki/The_First_and_Last_Freedom\n",
      "https://en.wikipedia.org/wiki/Ramesh_Thilak\n",
      "https://twitter.com/thilak_ramesh\n",
      "https://www.cs.washington.edu/people/faculty/arvind/teaching\n",
      "https://en.wikipedia.org/wiki/Area_codes_518_and_838\n",
      "https://www.cs.washington.edu/people/faculty/arvind/students\n",
      "http://t2.gstatic.com/licensed-image%3Fq%3Dtbn:ANd9GcQWefjUT6mdirnl_qEvYXTSEpYEFwefAacNHMummBkg3SX6wqoGSNVt8PjYPtqzrwTj\n",
      "https://www.reddit.com/r/kollywood/comments/1e1bv71/sujatha_is_overhyped_shankar_can_survive_without/\n",
      "https://www.wikihow.com/838-Angel-Number\n",
      "/search%3Fq%3Dsujatha%26sca_esv%3D969c93d55fac3d4d%26sca_upv%3D1%26tbm%3Dshop%26source%3Dlnms%26ved%3D1t:200713%26ictx%3D111\n",
      "https://www.dea.gov/drug-information/drug-scheduling\n",
      "https://www.838coatings.com/\n",
      "https://mail.google.com/mail/u/0/\n",
      "https://takeout.google.com/%3Fpli%3D1\n",
      "https://www.imdb.com/name/nm0837675/\n",
      "https://accounts.google.com/ServiceLogin%3Fcontinue%3Dhttps://www.google.com/search%253Fq%253D1%26hl%3Den\n",
      "https://www.tsa.gov/travel/frequently-asked-questions/what-3-1-1-liquids-rule\n",
      "https://en.wikipedia.org/wiki/Jiddu_Krishnamurti_bibliography\n",
      "https://accounts.google.com/ServiceLogin%3Fcontinue%3Dhttps://www.google.com/search%253Fq%253Dthilak%26hl%3Den\n",
      "https://journalism.uiowa.edu/people/sujatha-sosale\n",
      "https://en.wikipedia.org/wiki/Krishnamurti\n",
      "https://www.instagram.com/actress.sujatha/%3Fhl%3Den\n",
      "https://en.wikipedia.org/wiki/Jiddu_Krishnamurti\n",
      "https://www.instagram.com/sowmyak/%3Fhl%3Den\n",
      "https://open.spotify.com/track/0Jlcvv8IykzHaSmj49uNW8\n",
      "http://www.rohanrhythm.com/bio\n",
      "https://www.tiktok.com/%40andthereishappiness/video/7238586532293102853%3Flang%3Den\n",
      "/search%3Fq%3Dkrishnamurthy%26sca_esv%3D969c93d55fac3d4d%26sca_upv%3D1%26tbm%3Dshop%26source%3Dlnms%26ved%3D1t:200713%26ictx%3D111\n",
      "https://support.google.com/webmasters/answer/7489871%3Fhl%3Den\n",
      "/search%3Fq%3D838%26sca_esv%3D969c93d55fac3d4d%26tbm%3Dshop%26source%3Dlnms%26ved%3D1t:200713%26ictx%3D111\n",
      "https://www.gsb.stanford.edu/faculty-research/faculty/arvind-krishnamurthy\n",
      "https://www.cs.washington.edu/people/faculty/arvind/awardpapers\n",
      "https://maps.google.com/maps%3Fq%3Dthilak%26um%3D1%26ie%3DUTF-8%26ved%3D1t:200713%26ictx%3D111\n",
      "https://www.youtube.com/watch%3Fv%3DQm4jxdohjhY\n",
      "https://www.youtube.com/watch%3Fv%3DKsZ6tROaVOQ\n",
      "https://maps.google.com/maps%3Fq%3D838%26um%3D1%26ie%3DUTF-8%26ved%3D1t:200713%26ictx%3D111\n"
     ]
    }
   ],
   "source": [
    "# Paths to the new resume and existing resumes\n",
    "new_resume_path = r'C:\\Users\\thila\\Downloads\\Untitled Folder\\Thilak_SujathaKrishnamurthy_resume (Sdev).pdf'  # Replace with the path to your new resume\n",
    "existing_resumes_paths = [\n",
    "    r'C:\\Users\\thila\\Downloads\\Untitled Folder\\Thilak_SujathaKrishnamurthy_resume (ML).pdf',  # Replace with paths to your existing resumes\n",
    "    r'C:\\Users\\thila\\Downloads\\Untitled Folder\\Thilak_SujathaKrishnamurthy_resume (1) (1).docx',\n",
    "    r'C:\\Users\\thila\\Downloads\\Untitled Folder\\THILAK SUJATHA KRISHNAMURTHY_SDE.pdf'\n",
    "    # Add more paths if you have more resumes to compare against\n",
    "]\n",
    "\n",
    "def detect_plagiarism_and_score(new_resume_path, existing_resumes_paths):\n",
    "    print(\"Starting plagiarism detection...\")  # Debugging\n",
    "\n",
    "    # Extract text from the new resume\n",
    "    if new_resume_path.endswith('.pdf'):\n",
    "        new_resume_text = extract_text_from_pdf(new_resume_path)\n",
    "    elif new_resume_path.endswith('.docx'):\n",
    "        new_resume_text = extract_text_from_docx(new_resume_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "    print(f\"Extracted new resume text (first 500 characters): {new_resume_text[:500]}\")  # Print the first 500 characters for verification\n",
    "\n",
    "    # Clean the extracted text\n",
    "    new_resume_text = clean_text(new_resume_text)\n",
    "    print(f\"Cleaned new resume text (first 10 tokens): {new_resume_text[:10]}\")  # Print the first 10 tokens for verification\n",
    "\n",
    "    # Extract and clean text from existing resumes\n",
    "    existing_resumes_texts = []\n",
    "    for path in existing_resumes_paths:\n",
    "        if path.endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(path)\n",
    "        elif path.endswith('.docx'):\n",
    "            text = extract_text_from_docx(path)\n",
    "        cleaned_text = clean_text(text)\n",
    "        existing_resumes_texts.append(cleaned_text)\n",
    "        print(f\"Extracted and cleaned existing resume text (first 10 tokens): {cleaned_text[:10]}\")  # Print the first 10 tokens for verification\n",
    "\n",
    "    # Convert lists of tokens back to strings for comparison\n",
    "    new_resume_text = ' '.join(new_resume_text)\n",
    "    existing_resumes_texts = [' '.join(text) for text in existing_resumes_texts]\n",
    "\n",
    "    # Compare the new resume with existing ones\n",
    "    similarity_scores = compare_resumes(new_resume_text, existing_resumes_texts)\n",
    "    print(f\"Similarity scores: {similarity_scores}\")\n",
    "\n",
    "    plagiarism_score = calculate_plagiarism_score(similarity_scores)\n",
    "    print(f\"Plagiarism score: {plagiarism_score}\")\n",
    "\n",
    "    # Search online for possible sources\n",
    "    sources_found = []\n",
    "    for snippet in new_resume_text.split()[:5]:  # Take the first 5 words to search\n",
    "        links = search_online(snippet)\n",
    "        urls = extract_urls(links)\n",
    "        sources_found.extend(urls)\n",
    "        print(f\"Snippet: {snippet}, Number of URLs found: {len(urls)}\")\n",
    "\n",
    "    # Remove duplicates from the sources\n",
    "    unique_sources = list(set(sources_found))\n",
    "\n",
    "    # Calculate overall score\n",
    "    overall_score = calculate_overall_score(plagiarism_score, len(unique_sources))\n",
    "    print(f\"Overall score: {overall_score}\")\n",
    "\n",
    "    return {\n",
    "        \"plagiarism_score\": plagiarism_score,\n",
    "        \"num_sources\": len(unique_sources),\n",
    "        \"overall_score\": overall_score,\n",
    "        \"sources\": unique_sources\n",
    "    }\n",
    "\n",
    "# Call the main function to get the results\n",
    "results = detect_plagiarism_and_score(new_resume_path, existing_resumes_paths)\n",
    "\n",
    "# Output the results\n",
    "print(\"Plagiarism Score:\", results[\"plagiarism_score\"])\n",
    "print(\"Number of Sources Found:\", results[\"num_sources\"])\n",
    "print(\"Overall Score:\", results[\"overall_score\"])\n",
    "print(\"Sources Found:\")\n",
    "for source in results[\"sources\"]:\n",
    "    print(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f7a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [13/Aug/2024 20:12:21] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/Aug/2024 20:12:21] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [13/Aug/2024 20:12:39] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#Flask App\n",
    "from flask import Flask, render_template_string, request\n",
    "import os\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Set up upload folder\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "# Dummy function to simulate plagiarism detection\n",
    "def detect_plagiarism_and_score(new_resume_path, existing_resumes_paths):\n",
    "    # Here we would have your existing function implementation.\n",
    "    # For simplicity, this function will return a dummy result.\n",
    "    return {\n",
    "        \"plagiarism_score\": 0.75,\n",
    "        \"num_sources\": 5,\n",
    "        \"overall_score\": 0.80,\n",
    "        \"sources\": [\n",
    "            \"https://example.com/source1\",\n",
    "            \"https://example.com/source2\",\n",
    "            \"https://example.com/source3\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    # Simple HTML form for file upload\n",
    "    return render_template_string('''\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>Resume Plagiarism Checker</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Upload Your Resume</h1>\n",
    "        <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
    "            <input type=\"file\" name=\"resume\" required>\n",
    "            <button type=\"submit\">Check Plagiarism</button>\n",
    "        </form>\n",
    "    </body>\n",
    "    </html>\n",
    "    ''')\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file():\n",
    "    if 'resume' not in request.files:\n",
    "        return 'No file uploaded', 400\n",
    "    \n",
    "    file = request.files['resume']\n",
    "    if file.filename == '':\n",
    "        return 'No file selected', 400\n",
    "    \n",
    "    # Save the uploaded file\n",
    "    filename = secure_filename(file.filename)\n",
    "    file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "    file.save(file_path)\n",
    "\n",
    "    # Paths to existing resumes\n",
    "    existing_resumes_paths = [\n",
    "        r'C:\\Users\\thila\\Downloads\\Untitled Folder\\Thilak_SujathaKrishnamurthy_resume (ML).pdf',\n",
    "        r'C:\\Users\\thila\\Downloads\\Untitled Folder\\Thilak_SujathaKrishnamurthy_resume (1) (1).docx',\n",
    "        r'C:\\Users\\thila\\Downloads\\Untitled Folder\\THILAK SUJATHA KRISHNAMURTHY_SDE.pdf'\n",
    "    ]\n",
    "\n",
    "    # Run the plagiarism detection\n",
    "    results = detect_plagiarism_and_score(file_path, existing_resumes_paths)\n",
    "\n",
    "    # Display results\n",
    "    return render_template_string('''\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>Plagiarism Results</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Plagiarism Check Results</h1>\n",
    "        <p><strong>Plagiarism Score:</strong> {{ results.plagiarism_score }}</p>\n",
    "        <p><strong>Number of Sources Found:</strong> {{ results.num_sources }}</p>\n",
    "        <p><strong>Overall Score:</strong> {{ results.overall_score }}</p>\n",
    "        <h2>Sources Found:</h2>\n",
    "        <ul>\n",
    "            {% for source in results.sources %}\n",
    "                <li><a href=\"{{ source }}\" target=\"_blank\">{{ source }}</a></li>\n",
    "            {% endfor %}\n",
    "        </ul>\n",
    "        <a href=\"/\">Check Another Resume</a>\n",
    "    </body>\n",
    "    </html>\n",
    "    ''', results=results)\n",
    "\n",
    "# Run the Flask app within the notebook\n",
    "from werkzeug.serving import run_simple\n",
    "run_simple('localhost', 5000, app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9158c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
